<!DOCTYPE HTML>
<html>
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-151940545-2"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-151940545-2');
		</script>

		<title>Ning-Hsu Wang</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="author" content="Ning-Hsu Wang" />
		<meta name="keywords" content="Ning-Hsu Wang, Albert, Albert Wang, deep learning, internship, National Tsing Hua University, NTHU, nthu, 360, 360SD-Net"/>
		<meta name="description" content="Ning-Hsu Wang Personal Webpage" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="icon" type="image/png" href="images/logo.png">
		<!-- Fix and check if the code works for preview:
		https://medium.com/@Scotty_Lingner/linkedin-link-preview-images-not-showing-up-try-this-3cd80043b5bb -->
		<meta prefix="og: http://ogp.me/ns#" property="og:site_name" content="Ning-Hsu Wang" />
		<meta prefix="og: http://ogp.me/ns#" property="og:image" content="https://albert100121.github.io/images/preview_image.jpg" />
		<meta prefix="og: http://ogp.me/ns#" property="og:image:type" content="image/jpg" />
		<meta prefix="og: http://ogp.me/ns#" property="og:description" content="Graduate research student at VSLab, NTHU." />
		<!-- The sample from linkedin 
		LinkedIn requires the prefix on that OG tag. Facebook doesn’t require it, but it does no harm. So, leave it, mmkay? -->
		<meta prefix="og: http://ogp.me/ns#" property="og:type" content="Website" />
		<meta prefix="og: http://ogp.me/ns#" property="og:title" content="Albert Wang" />
		<!-- <meta prefix="og: http://ogp.me/ns#" property="og:description" content="The description of your page." /> -->
		<!-- <meta prefix="og: http://ogp.me/ns#" property="og:image" content="The image url" /> -->
		<meta prefix="og: http://ogp.me/ns#" property="og:url" content="https://albert100121.github.io" />
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Header -->
					<header id="header">
						<span class="avatar"><img src="images/albertwang.jpg" alt="" /></span>
						<h1><strong>Ning-Hsu (Albert) Wang</strong></h1>
						<p style="text-align:justify;margin-left: 10%;margin-right: 10%;"><strong> I am a Master's new grad with a focus on Computer Vision and Deep Learning. Previously, I was a Computer Vision research intern at <a href="https://www.mediatek.tw/">MediaTek, Taiwan</a>.
							I received my Master's degree in 
							<a href="http://web.ee.nthu.edu.tw/bin/home.php?Lang=en">Electrical Engineering</a> 
							from 
							<a href="http://nthu-en.web.nthu.edu.tw/bin/home.php">National Tsing Hua Unviersity (NTHU)</a>
							advised by Prof. 
							<a href="http://aliensunmin.github.io/">Min Sun</a>.
							During my graduate research, I worked with 
							<a href="https://walonchiu.github.io/">Prof. Wei-Chen Chiu</a>
							and
							<a href="https://sites.google.com/site/yihsuantsai/">Dr. Yi-Hsuan Tsai</a> 
							on 360<span>°</span> Stereo Depth Project.
							Afterward, I worked with 
							<a href="https://htchen.github.io/">Prof. Hwann-Tzong Chen</a> 
							on Planar Reconstruction.
							My research interest lies in Deep Learning and its applications, especially focusing on 360<span>°</span> VR/AR application and Robotics Perceptions.<br>
							<!-- I'm recently working on 360<span>°</span> Stereo Depth Estimation and 360<span>°</span> Monocular Planar Reconstruction. -->
							My personal hobbies include listening to music, restaurant/cafe hopping and badminton.<br>
							<span style="font-weight: bold; font-size: 1.15em">I'm actively looking for internship/permanent positions for Master's graduates. <a href="images/Albert_Wang_Resume.pdf">[CV]</a></span>
							</strong>
						</p>
						<h1 id="main">
							<!-- Sections -->
							<ul class="icons">
								<li><a href="#News">News</li>
								<li><a href="#edu">Education</li>
								<li><a href="#exp">Experience</li>
								<li><a href="#publication">Publication</li>
								<li><a href="#project">Project</li>
								<!-- <li><a href="#contact">contact</li> -->
							</ul>
						</h1>
						<ul class="icons">
							<li><a href="mailto:albert100121@gapp.nthu.edu.tw" class="icon style2 fa-envelope-o"><span class="label">Email</span></a></li>
							<li><a href="https://github.com/albert100121" class="icon style2 fa-github"><span class="label">Github</span></a></li>
							<!-- <li><a href="images/Ning_Hsu_Wang_Resume.pdf" class="icon style2 fa-file-text-o"><span class="label">CV</span></a></li> -->
							<li><a href="images/Albert_Wang_Resume.pdf" class="icon style2 fa-file-text-o"><span class="label">CV</span></a></li>
							<li><a href="http://www.linkedin.com/in/ning-hsu-albert-wang" class="icon style2 fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://twitter.com/Albert_NH_Wang" class="icon style2 fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://scholar.google.com/citations?user=8kYY700AAAAJ&hl=zh-TW"class="icon style2 fa-google"><span class="label">Google Scholar</span></a></li>
						</ul>
					</header>

					<div id="main">
						<article id="News">
							<h2><b>News</b></h2>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[07/2021] <strong>One ICCV 2021 paper accepted!!!</strong></li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[03/2021] One CVPR 2021 paper accepted as Oral Paper!!!</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[02/2021] Finish my internship at MediaTek.</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[10/2020] Finish my military training.</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[08/2020] Receive my M.Sc. degree from National Tsing Hua University.</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[07/2020] Selected as the honorary member of the <a href="http://www.phitauphi.org.tw/"><strong>Phi Tau Phi Scholastic Honor Society of the Republic of China</strong></a>.</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[02/2020] Join <a href="https://www.mediatek.com">MediaTek</a> as a Computer Vision Research Intern.</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[01/2020] One <a href="https://www.icra2020.org/">ICRA 2020</a> paper accepted!!!</li>
							<li style="font-weight: bold; margin-left: 5%; font-size: 1em">[08/2019] One <a href="http://iccv2019.thecvf.com/">ICCV19</a> <a href="https://360pi.github.io/iccv19/index.html">360 Perception and Interaction</a> paper accepted!!!</li>
							<!-- <p style="font-weight: bold; margin-left: 15%; font-size: 1.25em">&nbsp;[10/2020] Finished my military training.</p>
							<p style="font-weight: bold; margin-left: 15%; font-size: 1.25em">&nbsp;[08/2020] Receive my M.Sc. degree from National Tsing Hua University.</p>
							<a href="http://www.phitauphi.org.tw/"><img src="images/phi_tau_phi.gif" width=15%></a>
							<p style="font-weight: bold; margin-left: 15%; font-size: 1.25em">&nbsp;[07/2020] Selected as the honorary member of the <a href="http://www.phitauphi.org.tw/">Phi Tau Phi Scholastic Honor Society of the Republic of China</a>.</p>
							<a href="https://www.icra2020.org/"><img src="images/project_img/ICRA_logo.jpg" width=15%></a>
							<p style="font-weight: bold; margin-left: 15%; font-size: 1.25em">&nbsp;[01/2020] One <a href="https://www.icra2020.org/">ICRA 2020</a> paper accepted!!!</p>
							<a href="http://iccv2019.thecvf.com/"><img src="images/project_img/ICCV_logo.jpg" width=15%></a>
							<p style="font-weight: bold; margin-left: 15%; font-size: 1.25em">&nbsp;[08/2019] One <a href="http://iccv2019.thecvf.com/">ICCV19</a> <a href="https://360pi.github.io/iccv19/index.html">360 Perception and Interaction</a> paper accepted!!!</p> -->
						</article><br>
						<article id="edu">
							<h2>Education</h2>
							<div style="font-weight: bold; margin-left: 5%">National Tsing-Hua University<span style="font-weight: normal;">, Hsinchu, Taiwan</span><span style="float:right;">2018.1 - 2020.7</span></div>
							<ul style="padding-left: 5%; margin-left: 5%">
								<li>M.Sc. Electrical Engineering</li>
								<li>Vision Science Lab (VSLAB)</li>
								<li>Advised by Prof. <a href="http://aliensunmin.github.io/">Min Sun</a></li>
								<li>Concentrate on Computer Vision and Deep Learning researches</li>
							</ul>
							<div style="font-weight: bold; margin-left: 5%">National Chiao-Tung University<span style="font-weight: normal;">, Hsinchu, Taiwan</span><span style="float:right;">2013.9 - 2017.6</span></div>
							<ul style="padding-left: 5%; margin-left: 5%">
								<li>B.Sc. Mechanical Engineering</li>
								<li>Concentrate on Autonomous Control and Robotics</li>
							</ul>
						</article>
						<article id="exp">
								<h2>Experiences</h2>
								<div style="font-weight: bold; margin-left: 5%">Research Intern, MediaTek
									<span style="float: right; margin-left: 5%">2020.2 - 2021.2</span></div>
									<ul style="padding-left: 5%; margin-left: 5%">
										<!-- <li>Computer Vision and Perception</li>
										<li>Research oriented internship with topics related to Stereo Matching, Disparity Estimation, Light- Field Camera, DoF (Depth of Field) Images and Blur/Bokeh Effects.</li> -->
										<li>Worked on research topics related to stereo matching and depth estimation on images with blur/bokeh effects (shallow DoF) <b>(ICCV 2021)</b>.</li>
										<li>Presented a new dataset for model training on blurred images.</li>
										<li>Proposed a new unsupervised training technique on depth estimation.</li>
									</ul>	
								<div style="font-weight: bold; margin-left: 5%">Graduate Research Assistant, VSLAB<span style="font-weight: normal;"> - advised by Prof. <a href="http://aliensunmin.github.io/">Min Sun</a></span>
									<span style="float: right; margin-left: 5%">2018.1 - 2020.7</span></div>
								<ul style="padding-left: 5%; margin-left: 5%">
									<!-- <li>360<span>°</span> Stereo Depth Estimation</li>
									<li>360<span>°</span> Monocular Planar Reconstruction</li> -->
									<li>Led the 360<span>°</span> Stereo Project, advised by Prof. Min Sun, Prof. Wei-Chen Chiu and Dr. Yi-Hsuan Tsai <b>(ICRA 2020)</b>.</li>
									<li>Presented two 360<span>°</span> stereo datasets as well as a novel DNN targeting depth estimation on 360<span>°</span> stereo images.</li>
									<li>Worked on Planar Reconstruction, co-advised by Prof. Hwann-Tzong Chen <b>(CVPR 2021 Oral)</b>.</li>
									<li>Proposed a new benchmark and a new method leveraging the phenomenon of indoor human structures and 360<span>°</span> images for indoor panorama planar reconstruction.</li>
								</ul>			
								<div style="font-weight: bold; margin-left: 5%">Technical Lead, <a href="https://www.entrepreneurship.net.tw/">Young Entrepreneurs of the Future</a>, <a href="https://www.epoch.org.tw/">Epoch Foundation</a>
									<span style="float: right;">2018.1 - 2018.07</span></div>
									<ul style="padding-left: 5%; margin-left: 5%">
										<!-- <li>Nationwide Startup Competition</li>
										<li><strong>Second Place</strong> in Garage Party</li> -->
										<li>Led a technical team in a nationwide startup competition and won Second Place in the first stage of the two stages.</li>
										<li>Designed an electronic mask-like device with active noise canceling for both meeting and gaming.</li>
									</ul>
								<div style="font-weight: bold; margin-left: 5%">On-site Engineer, Atos
									<span style="float: right;">2017.08</span></div>
									<ul style="padding-left: 5%; margin-left: 5%">
										<li>29th Summer Universiade Internet System Maintenance</li>
									</ul>
								<div style="font-weight: bold; margin-left: 5%">Contestant, Tokyo Electron Limited Robot Combat, Tokyo Electron
									<span style="float: right;">2017</span></div>
									<ul style="padding-left: 5%; margin-left: 5%">
										<li>Robotic Construction/Combat Competition</li>
									</ul>
							<!-- <div class="close">Close</div> -->
						</article>
						<article id="publication">
							<h2>Publications</h2>
							<a href="https://albert100121.github.io/AiFDepthNet-Project-Page/">
							<figure>
								<!-- <img class="project" src="images/Lock2.jpg"> -->
								<img class="project" src="images/Bridging_ICCV2021/arch.pdf">
								<div style="text-indent:0em; text-align:justify; font-weight: bold; margin-left: 23%" class="project_cap" >Bridging Unsupervised and Supervised Depth from Focus via All-in-Focus Supervision</div></a>
								<div class="project_cap author" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="http://albert100121.github.io"><b>Ning-Hsu Wang</b></a>, 
									<a href="https://www.linkedin.com/in/ren-wang-61b273160/?originalSubdomain=tw">Ren Wang</a>, 
									<a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/">Yu-Lun Liu</a>, 
									<a href="https://www.linkedin.com/in/yu-hao-huang-72821060/?originalSubdomain=tw">Yu-Hao Huang</a>, 
									<a href="https://scholar.google.com/citations?user=0O9rukQAAAAJ&hl=en">Yu-Lin Chang</a>, 
									<a href="https://tw.linkedin.com/in/chia-ping-chen-81674078">Chia-Ping Chen</a>, 
									<a href="https://corp.mediatek.com/investor-relations/corporate-governance/corporate-management">Kevin Jou</a>
								</div>
								<div class="project_cap submission" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="http://iccv2021.thecvf.com/home">IEEE/CVF International Conference on Computer Vision (ICCV 2021)</a></div>
								<div class="project_cap" style="margin-left: 20%">&nbsp;Project Page Coming Soon!!!</div>
							</figure><br><br>
							<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Indoor_Panorama_Planar_3D_Reconstruction_via_Divide_and_Conquer_CVPR_2021_paper.html">
							<figure>
								<!-- <img class="project" src="images/Lock2.jpg"> -->
								<img class="project" src="images/project_img/model_2.png">
								<div style="text-indent:0em; text-align:justify; font-weight: bold; margin-left: 23%" class="project_cap" >Indoor Panorama Planar 3D Reconstruction via Divide and Conquer</div></a>
									<!-- <div class="project_cap submission" style="margin-left: 20%">&nbsp;&nbsp;In Submission</div> -->
									<!-- <ul style="padding-left: 5%; margin-left: 20%">
									</ul> -->
								<div class="project_cap author" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="https://sunset1995.github.io">Cheng Sun</a>, <a href="https://chiweihsiao.github.io">Chi-Wei Hsiao</a>, <a href="http://albert100121.github.io"><b>Ning-Hsu Wang</b></a>, <a href="http://aliensunmin.github.io/">Min Sun</a>, Hwann-Tzong Chen</div>
								<div class="project_cap submission" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="http://cvpr2021.thecvf.com">IEEE/CVF Conference on Computer Vision and Pattern Recognition 2021 Oral (CVPR 2021 Oral)</a></div>
								<br>
								<div class="project_cap Coming" style="text-indent:0em; text-align:justify; margin-left: 23%">&nbsp;&nbsp;<a href="https://arxiv.org/abs/2106.14166" style="border-width:2px;border-style:solid;border-color:rgb(255, 255, 255);padding:4px;"><strong>Preprint</strong></a>&nbsp;&nbsp;<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Indoor_Panorama_Planar_3D_Reconstruction_via_Divide_and_Conquer_CVPR_2021_paper.html" style="border-width:2px;border-style:solid;border-color:rgb(255, 255, 255);padding:4px;"><strong>Paper</strong></a></div>
							</figure><br>
							<a href="http://albert100121.github.io/360SD-Net-Project-Page/">
								<figure>
								<img class="project" src="images/project_img/git_small.gif">
								<!-- <img src="images/project_img/video_format_v2.gif" class="project">&nbsp;&nbsp;&nbsp;<b>360SD-Net: 360<span>°</span> Stereo Depth Estimation with Learnable Cost Volume</b></img> -->
								<!-- <figcaption>&nbsp;&nbsp;&nbsp;<b>360SD-Net: 360<span>°</span> Stereo Depth Estimation with Learnable Cost Volume</b></figcaption> -->
								<div style="text-indent:0em; text-align:justify; font-weight: bold; margin-left: 23%" class="project_cap" >360SD-Net: 360<span>°</span> Stereo Depth Estimation with Learnable Cost Volume</div>
								<div class="project_cap author" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="http://albert100121.github.io"><b>Ning-Hsu Wang</b></a>, Bolivar Solarte, <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>, <a href="https://walonchiu.github.io/">Wei-Chen Chiu</a>, <a href="http://aliensunmin.github.io/">Min Sun</a></div>
								<div class="project_cap submission" style="text-indent:0em; text-align:justify; margin-left: 23%"><a href="https://www.icra2020.org/">Internationl Conference on Robotics and Automation 2020 (ICRA 2020)</a></div>
								<div class="project_cap submission" style="text-indent:0em; text-align:justify; margin-left: 23%">Short Version in <a href="http://iccv2019.thecvf.com/">ICCV19</a>: <a href="https://360pi.github.io/iccv19/index.html">360PI Workshop</a></div>
								<br>
								<div class="project_cap Coming" style="text-indent:0em; text-align:justify; margin-left: 23%">&nbsp;&nbsp;<a href="https://arxiv.org/abs/1911.04460" style="border-width:2px;border-style:solid;border-color:rgb(255, 255, 255);padding:4px;"><strong>Preprint</strong></a>&nbsp;&nbsp;<a href="https://github.com/albert100121/360SD-Net" style="border-width:2px;border-style:solid;border-color:rgb(255, 255, 255);padding:4px;"><strong>Code</strong></a>&nbsp;&nbsp;<a href="http://albert100121.github.io/360SD-Net-Project-Page/" style="border-width:2px;border-style:solid;border-color:rgb(255, 255, 255);padding:4px;"><strong>Project Page</strong></a></div>
								<!-- <div class="project_cap" style="margin-left: 20%">&nbsp;Project Page Coming Soon!!!</div> -->
								<!-- <div class="project_img">360SD-Net: 360<span>°</span> Stereo Depth Estimation with Learnable Cost Volume</div> -->
								</figure>
							</a>
						</article><br><br>
						<article id="project">
							<h2>Project Highlights</h2>
							<figure>
								<img class="project" src="images/722.gif">
								<div style="font-weight: bold; margin-left: 20%" class="project_cap" ><a href="http://albert100121.github.io/360SD-Net-Project-Page/">360<span>°</span> Stereo Depth Estimation</a></div>
									<ul style="padding-left: 5%; margin-left: 20%">
										<li>Presented a new 360&deg; stereo dataset. </li>
										<li>Implementation of deep neural network baselines as well as conventional methods.</li>
										<li>Presented a deep nerual network with several novel modules for 360&deg; stereo depth estimation. </li>
									</ul>
							</figure>
							<a href="https://drive.google.com/file/d/1X_toESVjf84dssZ2IPUk95i-9laDBoHp/view">
								<figure>
									<img class="project" src="images/3D_Horror_Scene.gif">
									<!-- <div style="font-weight: bold; margin-left: 20%" class="project_cap" ><a href="https://drive.google.com/file/d/1X_toESVjf84dssZ2IPUk95i-9laDBoHp/view">3D Horror Scene: Horror Style Transfer Using 360<span>°</span> Views and 3D Reconstruction</div> -->
									<div style="font-weight: bold; margin-left: 20%" class="project_cap" ><a href="https://drive.google.com/file/d/1X_toESVjf84dssZ2IPUk95i-9laDBoHp/view">3D Horror Scene: Horror Style Transfer Using 360<span>°</span> Views and 3D Reconstruction</a></div>
									<ul style="padding-left: 5%; margin-left: 20%">
										<!-- <li>Collection of horror scene data.</li>
										<li>Implementation of CycleGAN for style transfer.</li>
										<li>Implementation of LayoutNet for 360&deg; layout reconstruction.</li> -->
										<li>Collected 5000 horror scene images with web crawling from YouTube horror game videos for style transfer training.</li>
										<li>Implemented CycleGAN for style transfer and LayoutNet for 360◦ layout reconstruction.</li>
										<li>Combined both model outputs (horror style 360◦ images and 3D room layout) to form a 3D model of horror rooms.</li>
									</ul>
								</figure>
							</a>
							<!-- <div style="font-weight: bold; margin-left: 5%" class="project_cap" ><a href="https://drive.google.com/file/d/1X_toESVjf84dssZ2IPUk95i-9laDBoHp/view">3D Horror Scene: Horror Style Transfer Using 360<span>°</span> Views and 3D Reconstruction</a></div>
								<ul style="padding-left: 5%; margin-left: 5%">
									<li>Collection of horror scene data.</li>
									<li>Implementation of CycleGAN for style transfer.</li>
									<li>Implementation of LayoutNet for 360&deg; layout reconstruction.</li>
								</ul>-->
							<figure>
								<img class="project" src="images/UAV_v2.gif">
								<!-- <div style="font-weight: bold; margin-left: 20%" class="project_cap" >Design and implementation of Logistic UAV (Unmanned Aerial Vehicle)</div> -->
								<div style="font-weight: bold; margin-left: 20%" class="project_cap" >Unmanned Aircraft Remote Delivery System (Drone)</div>
									<ul style="padding-left: 5%; margin-left: 20%">
										<!-- <li>Design and implementation of UAV mechanism. </li>
										<li>Design and implementation of unloading mechanism and motor control system.</li>
										<li>Design of UAV surveillance system.</li>
										<li>Demostration of UAV control for unseen location object unloading</li> -->
										<li>Designed and implemented the drone mechanism, motor control, delivery, and real-time surveillance system.</li>
										<li>Demonstrated the UAV control for unseen location object delivery with a load of 300g.</li>
										<br><br>
									</ul>
							</figure>
							<figure>
								<img class="project" src="images/KNR.jpg">
								<div style="font-weight: bold; margin-left: 20%" class="project_cap" >KNR Robot Navigation and Object Detection in Maze</div>
									<ul style="padding-left: 5%; margin-left: 20%">
										<!-- <li>Design and implementation of KNR mechanism and ultrasonic avoidance system.</li>
										<li>LabVIEW programming of motor control, sensor feedback and image processing.</li> -->
										<li>Designed and manufactured the KNR mechanism with multi-sensor (camera, ultrasonic and infrared sensor).</li>
										<li>Programmed the navigation system, including motor control, multi-sensor feedback, and image processing in LabVIEW.</li>
									</ul>
							</figure>
							<div style="font-weight: bold; margin-left: 20%" class="project_cap" >Validation of The Lambda Method for Integer Ambiguity Estimation </div>
								<ul style="padding-left: 5%; margin-left: 20%">
									<li>Implementation of The Lambda Method for Integer Ambiguity Estimation with Matlab simulation.</li>
								</ul>
						</article>
						
						
					</div>

				<!-- Main -->
					<!-- <section id="main">
						<ul class="icons">
							<li><a href="#about">About</li>
						</ul>
						<ul class="icons">
							<li><a href="#experience">experience</li>
						</ul>
						<ul class="icons">
							<li><a href="#publication">publication</li>
						</ul>
						<ul class="icons">
							<li><a href="#contact">contact</li>
						</ul>
					</section> -->

				<!-- Footer -->
				<!--
					<footer id="footer">
						<p>&copy; Untitled. All rights reserved. Design: <a href="http://templated.co">TEMPLATED</a>. Demo Images: <a href="http://unsplash.com">Unsplash</a>.</p>
					</footer>
				-->
					<footer id="footer">
						<p> &copy; A.WangTW</p>
					</footer>
			</div>
			<!-- <div id="bg">
				::before
				::after
			</div> -->
		<!-- Scripts -->
		
			<!-- <script src="assets/js/jquery.min.js"></script> -->
			<!-- <script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/main.js"></script> -->
		
	</body>
</html>